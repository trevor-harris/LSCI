{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b7ab1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.stats as stats\n",
    "from jax import jacfwd, jacrev\n",
    "from jax import vmap, grad, jit, random\n",
    "from jax.tree_util import tree_map, tree_flatten, tree_unflatten, tree_leaves\n",
    "\n",
    "import torch_harmonics as th\n",
    "from torch_harmonics.random_fields import GaussianRandomFieldS2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from flax import nnx\n",
    "import optax\n",
    "import pcax\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a92f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../methods')\n",
    "import lsci, supr, conf, uqno\n",
    "os.chdir('../gpsims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a868a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(lower, upper, residual):\n",
    "    return jnp.mean((residual > lower)*(residual < upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bc2a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, lag, horizon):\n",
    "    horizon = horizon-1\n",
    "    y_t = data[(lag + horizon):][:,None]\n",
    "    x_t = np.stack([data[(lag-i-1):(-(i+1+horizon))] for i in range(lag)], axis = 1)\n",
    "    return x_t.copy(), y_t.copy()\n",
    "\n",
    "def torch2jax(x):\n",
    "    return jnp.array(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73293bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANO_layer(nnx.Module):\n",
    "    def __init__(self, width, rngs: nnx.Rngs):\n",
    "        self.linear = nnx.Linear(width, width, rngs=rngs)\n",
    "        # self.bn = nnx.BatchNorm(dmid, rngs=rngs)\n",
    "        # self.dropout = nnx.Dropout(0.2, rngs=rngs)\n",
    "        self.linear_out = nnx.Linear(width, width, rngs=rngs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # channel mix\n",
    "        h = self.linear(x)\n",
    "\n",
    "        # spatial mix\n",
    "        g = jnp.mean(x, axis = (1, 2))[:,None,None,:]\n",
    "\n",
    "        # sum\n",
    "        x = h + g\n",
    "        x = nnx.relu(x)\n",
    "\n",
    "        return self.linear_out(x)\n",
    "\n",
    "class encode_layer(nnx.Module):\n",
    "    def __init__(self, in_dim, out_dim, rngs):\n",
    "        self.linear = nnx.Linear(in_dim, out_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepANO(nnx.Module):\n",
    "    def __init__(self, in_dim, width, out_dim, rngs):\n",
    "        self.encode_layer = encode_layer(in_dim, width, rngs)\n",
    "        self.ano1 = ANO_layer(width, rngs)\n",
    "        self.ano2 = ANO_layer(width, rngs)\n",
    "        self.ano3 = ANO_layer(width, rngs)\n",
    "        self.decode_layer = encode_layer(width, out_dim, rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encode_layer(x)\n",
    "        x = self.ano1(x)\n",
    "        x = self.ano2(x)\n",
    "        x = self.ano3(x)\n",
    "        x = self.decode_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0ea8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANO_layer(nnx.Module):\n",
    "    def __init__(self, width, rngs: nnx.Rngs):\n",
    "        self.conv = nnx.Conv(width, width, (1, 1), rngs=rngs)\n",
    "        self.conv_out = nnx.Conv(width, width, (1, 1), rngs=rngs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # channel mix\n",
    "        h = self.conv(x)\n",
    "\n",
    "        # spatial mix\n",
    "        g = jnp.mean(x, axis = (1, 2))[:,None,None,:]\n",
    "\n",
    "        # sum\n",
    "        x = h + g\n",
    "        x = nnx.relu(x)\n",
    "\n",
    "        return self.conv_out(x)\n",
    "\n",
    "class encode_layer(nnx.Module):\n",
    "    def __init__(self, in_dim, out_dim, rngs):\n",
    "        self.conv = nnx.Conv(in_dim, out_dim, (1, 1), rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class DeepANO(nnx.Module):\n",
    "    def __init__(self, in_dim, width, out_dim, rngs):\n",
    "        self.encode_layer = encode_layer(in_dim, width, rngs)\n",
    "        self.ano1 = ANO_layer(width, rngs)\n",
    "        self.ano2 = ANO_layer(width, rngs)\n",
    "        self.ano3 = ANO_layer(width, rngs)\n",
    "        self.decode_layer = encode_layer(width, out_dim, rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encode_layer(x)\n",
    "        x = self.ano1(x)\n",
    "        x = self.ano2(x)\n",
    "        x = self.ano3(x)\n",
    "        x = self.decode_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62c5ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x, y):\n",
    "    def loss_fn(model):\n",
    "        y_pred = model(x)\n",
    "        return jnp.mean((y_pred - y) ** 2)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads)  # In place updates.\n",
    "\n",
    "    return loss\n",
    "\n",
    "def quant_step(model, optimizer, x, y):\n",
    "    def loss_fn(model):\n",
    "        quant = 1 - 0.1\n",
    "        y_pred = model(x)\n",
    "        y_abs = jnp.abs(y)\n",
    "        resid = y_abs - y_pred\n",
    "        loss = jnp.max(jnp.concat([quant * resid, -(1-quant) * resid], axis = 3), axis = 3)\n",
    "        return jnp.mean(loss)\n",
    "    \n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads)  # in-place updates\n",
    "\n",
    "    return loss\n",
    "\n",
    "train_step = nnx.jit(train_step)\n",
    "quant_step = nnx.jit(quant_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bfb254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 501\n",
    "s = jnp.linspace(-2*math.pi, 2*math.pi, n+1)\n",
    "amp = jnp.sin(s)\n",
    "sd = 1.25 + jnp.sin(s)\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xtrain = gp2d(n+1).numpy()\n",
    "xtrain = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xtrain)\n",
    "xtrain, ytrain = split_data(xtrain, 1, 1)\n",
    "xtrain = xtrain[:,0,:,:,None]\n",
    "ytrain = ytrain[:,0,:,:,None]\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xval = gp2d(n+1).numpy()\n",
    "xval = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xval)\n",
    "xval, yval = split_data(xval, 1, 1)\n",
    "xval = xval[:,0,:,:,None]\n",
    "yval = yval[:,0,:,:,None]\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xtest = gp2d(n+1).numpy()\n",
    "xtest = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xtest)\n",
    "xtest, ytest = split_data(xtest, 1, 1)\n",
    "xtest = xtest[:,0,:,:,None]\n",
    "ytest = ytest[:,0,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4573a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.Tensor(xtrain), torch.Tensor(ytrain))\n",
    "train_loader = DataLoader(train_data, batch_size = 30, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eece0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @nnx.jit  # Automatic state management\n",
    "# def train_step(model, optimizer, x, y):\n",
    "#     def loss_fn(model):\n",
    "#         y_pred = model(x)\n",
    "#         y_diff = jnp.diff(y_pred, axis = 0)\n",
    "#         return jnp.mean((y_pred - y) ** 2) + jnp.mean(y_diff**2)\n",
    "\n",
    "#     loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "#     optimizer.update(grads)  # In place updates.\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# epochs = 5\n",
    "# trace = []\n",
    "\n",
    "# model = ClimateNO(1, 32, 1, rngs=nnx.Rngs(0))\n",
    "# optim = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "# rng = random.PRNGKey(0)\n",
    "\n",
    "# for _ in trange(epochs):\n",
    "#     for xt, yt in tqdm(train_loader, leave = False):\n",
    "#         xt = torch2jax(xt)\n",
    "#         yt = torch2jax(yt)\n",
    "        \n",
    "#         loss = train_step(model, optim, xt, yt)\n",
    "#         trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2426e99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9aeb79de6c4a57bfb5478c043fb29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "trace = []\n",
    "lag, lead = 1, 1\n",
    "\n",
    "model = DeepANO(lag, 50, lead, rngs=nnx.Rngs(0))\n",
    "optim = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "for _ in trange(epochs):\n",
    "    for xt, yt in train_loader:\n",
    "        xt = torch2jax(xt)\n",
    "        yt = torch2jax(yt)\n",
    "        \n",
    "        loss = train_step(model, optim, xt, yt)\n",
    "        trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dd64157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145d9721b70d493db8ab77f462d8efc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quant = DeepANO(lag, 50, lead, rngs=nnx.Rngs(0))\n",
    "optim = nnx.Optimizer(quant, optax.adam(1e-3))\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "for _ in trange(epochs):\n",
    "    for xt, yt in train_loader:\n",
    "        xt = torch2jax(xt)\n",
    "        yt = torch2jax(yt)\n",
    "        \n",
    "        loss = quant_step(quant, optim, xt, yt)\n",
    "        trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "724c148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_step(model, optimizer, x, y):\n",
    "#     def loss_fn(model):\n",
    "#         quant = 1 - 0.1\n",
    "#         y_pred = model(x)\n",
    "#         y_abs = jnp.abs(y)\n",
    "#         resid = y_abs - y_pred\n",
    "#         loss = jnp.max(jnp.concat([quant * resid, -(1-quant) * resid], axis = 3), axis = 3)\n",
    "#         return jnp.mean(loss)\n",
    "    \n",
    "#     loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "#     optimizer.update(grads)  # in-place updates\n",
    "\n",
    "#     return loss\n",
    "# train_step = nnx.jit(train_step)\n",
    "\n",
    "# quant = DeepANO(1, 50, 1, nnx.Rngs(0))\n",
    "# optimizer = nnx.Optimizer(quant, optax.adam(1e-3)) \n",
    "\n",
    "# epochs = 100\n",
    "# nbat = 50\n",
    "# for _ in trange(epochs):\n",
    "#     for i in trange(xtrain.shape[0]//nbat, leave = False):\n",
    "#         xi = xtrain[i*nbat:(i+1)*nbat]\n",
    "#         yi = ytrain[i*nbat:(i+1)*nbat]\n",
    "\n",
    "#         loss = train_step(quant, optimizer, xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a93e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "yval_hat = model(xval)\n",
    "ytest_hat = model(xtest)\n",
    "yval_quant = quant(xval)\n",
    "ytest_quant = quant(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bca5de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nproj = 100\n",
    "gamma1 = 0.2\n",
    "alpha = 0.1\n",
    "nval = xval.shape[0]\n",
    "alpha1 = 1 - jnp.ceil((1-alpha) * (gamma1*nval + 1))/(gamma1*nval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d886b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "yval = yval.reshape(yval.shape[0], -1)\n",
    "yval_hat = yval_hat.reshape(yval_hat.shape[0], -1)\n",
    "pca_state = lsci.phi_state(yval, yval_hat, nproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fa730df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.03918276, dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UQNO lambda estimate\n",
    "yval_quant = yval.reshape(yval_quant.shape[0], -1)\n",
    "ytest_quant = ytest_quant.reshape(ytest_quant.shape[0], -1)\n",
    "\n",
    "alpha = 0.1\n",
    "delta = 0.1\n",
    "m = 30*60\n",
    "tau = 2 * jnp.sqrt(-jnp.log(delta)/(2*m))\n",
    "sg = jnp.abs(yval - yval_hat) / yval_quant\n",
    "sg = jnp.quantile(sg, 1-alpha+tau, axis = (1))\n",
    "nval = sg.shape[0]\n",
    "\n",
    "adj_alpha = 1 - jnp.ceil((nval + 1) * (delta - jnp.exp(-2*m*tau**2)))/nval\n",
    "lam_uqno = jnp.quantile(sg, adj_alpha)\n",
    "lam_uqno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9e46920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abd7bafe054487580cd84731dcaa1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nproj = 150\n",
    "gamma1 = 0.1\n",
    "alpha = 0.1\n",
    "nval = xval.shape[0]\n",
    "alpha1 = 1 - jnp.ceil((1-alpha) * (gamma1*nval + 1))/(gamma1*nval)\n",
    "\n",
    "lsc1_rc = []\n",
    "lsc1_width = []\n",
    "\n",
    "conf_rc = []\n",
    "conf_width = []\n",
    "\n",
    "supr_rc = []\n",
    "supr_width = []\n",
    "\n",
    "uqn1_rc = []\n",
    "uqn1_width = []\n",
    "\n",
    "yval = yval.reshape(yval.shape[0], -1)\n",
    "yval_hat = yval_hat.reshape(yval_hat.shape[0], -1)\n",
    "pca_state = lsci.phi_state(yval, yval_hat, nproj)\n",
    "\n",
    "rval = (yval - yval_hat).squeeze().reshape(-1, 30*60)\n",
    "rtest = (ytest - ytest_hat).squeeze().reshape(-1, 30*60)\n",
    "\n",
    "conf_lower, conf_upper = conf.conf_band(rval, pca_state, alpha)\n",
    "supr_lower, supr_upper = supr.supr_band(rval, alpha)\n",
    "uqn1_lower, uqn1_upper = uqno.uqno_band(ytest_quant, lam_uqno)\n",
    "\n",
    "for i in trange(0, 100):\n",
    "    # Oracle    \n",
    "    oracle_lower = jnp.min(rtest[i]) * jnp.ones((30*60,)) - 1e-7\n",
    "    oracle_upper = jnp.max(rtest[i]) * jnp.ones((30*60,)) + 1e-7\n",
    "    oracle_rc.append(risk(oracle_lower, oracle_upper, rtest[i]))\n",
    "    oracle_width.append(jnp.mean(oracle_upper - oracle_lower))\n",
    "    \n",
    "    # LSCI\n",
    "    lsc1_lower, lsc1_upper = lsci.lsci((yval - yval_hat).reshape(-1, 30*60), xval.reshape(-1, 30*60), xtest[i].reshape(-1, 30*60), pca_state, alpha1, gamma1, 2000)\n",
    "    lsc1_rc.append(risk(lsc1_lower, lsc1_upper, rtest[i]))\n",
    "    lsc1_width.append(jnp.median(lsc1_upper - lsc1_lower))\n",
    "    \n",
    "    # CONF \n",
    "    conf_rc.append(risk(conf_lower, conf_upper, rtest[i]))\n",
    "    conf_width.append(jnp.mean(conf_upper - conf_lower))\n",
    "    \n",
    "    # SUPR\n",
    "    supr_rc.append(risk(supr_lower, supr_upper, rtest[i]))\n",
    "    supr_width.append(jnp.mean(supr_upper - supr_lower))\n",
    "    \n",
    "    # UQNO\n",
    "    uqn1_rc.append(risk(uqn1_lower[i], uqn1_upper[i], rtest[i]))\n",
    "    uqn1_width.append(jnp.mean(uqn1_upper[i] - uqn1_lower[i]))\n",
    "\n",
    "    \n",
    "conf_rc = np.array(conf_rc)\n",
    "supr_rc = np.array(supr_rc)\n",
    "uqn1_rc = np.array(uqn1_rc)\n",
    "lsc1_rc = np.array(lsc1_rc)\n",
    "oracle_rc = np.array(oracle_rc)\n",
    "\n",
    "conf_width = np.array(conf_width)\n",
    "supr_width = np.array(supr_width)\n",
    "uqn1_width = np.array(uqn1_width)\n",
    "lsc1_width = np.array(lsc1_width)\n",
    "oracle_width = np.array(oracle_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec9af95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 1800)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_sd = np.std(rtest, axis = 1)\n",
    "\n",
    "risk_control = np.mean(oracle_rc >= 0.99), \\\n",
    "               np.mean(conf_rc >= 0.99), \\\n",
    "               np.mean(supr_rc >= 0.99), \\\n",
    "               np.mean(uqn1_rc >= 0.99), \\\n",
    "               np.mean(lsc1_rc >= 0.99), \\\n",
    "               np.mean(lsc2_rc >= 0.99)\n",
    "\n",
    "width = np.mean(oracle_width), \\\n",
    "        np.mean(conf_width), \\\n",
    "        np.mean(supr_width), \\\n",
    "        np.mean(uqn1_width), \\\n",
    "        np.mean(lsc1_width), \\\n",
    "        np.mean(lsc2_width)\n",
    "\n",
    "risk_cor = 0, \\\n",
    "           np.corrcoef([noise_sd, conf_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, supr_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, uqn1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc2_rc])[0,1]\n",
    "\n",
    "width_cor = np.corrcoef([noise_sd, oracle_width])[0,1], \\\n",
    "            0, \\\n",
    "            0, \\\n",
    "            np.corrcoef([noise_sd, uqn1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc2_width])[0,1]\n",
    "\n",
    "metrics = np.array([risk_control, risk_cor, width, width_cor]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16a9247e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5fa6552366446ea80055c5da0a7d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nproj = 90\n",
    "gamma1 = 0.1\n",
    "gamma2 = 0.05\n",
    "alpha = 0.1\n",
    "nval = xval.shape[0]\n",
    "alpha1 = 1 - jnp.ceil((1-alpha) * (gamma1*nval + 1))/(gamma1*nval)\n",
    "\n",
    "lsc1_rc = []\n",
    "lsc2_rc = []\n",
    "conf_rc = []\n",
    "supr_rc = []\n",
    "uqn1_rc = []\n",
    "oracle_rc = []\n",
    "\n",
    "lsc1_width = []\n",
    "lsc2_width = []\n",
    "conf_width = []\n",
    "supr_width = []\n",
    "uqn1_width = []\n",
    "oracle_width = []\n",
    "\n",
    "yval = yval.reshape(yval.shape[0], -1)\n",
    "yval_hat = yval_hat.reshape(yval_hat.shape[0], -1)\n",
    "pca_state = lsci.phi_state(yval, yval_hat, nproj)\n",
    "\n",
    "rval = (yval - yval_hat).squeeze().reshape(-1, 30*60)\n",
    "rtest = (ytest - ytest_hat).squeeze().reshape(-1, 30*60)\n",
    "\n",
    "conf_lower, conf_upper = conf.conf_band(rval, pca_state, alpha)\n",
    "supr_lower, supr_upper = supr.supr_band(rval, alpha)\n",
    "uqn1_lower, uqn1_upper = uqno.uqno_band(ytest_quant, lam_uqno)\n",
    "\n",
    "for i in trange(0, ytest.shape[0]):\n",
    "# for i in trange(0, 100):\n",
    "    \n",
    "    # LSCI\n",
    "    lsc1_lower, lsc1_upper = lsci.lsci(rval, xval.reshape(-1, 30*60), xtest[i].reshape(-1, 30*60), pca_state, alpha1, gamma1, 2000)\n",
    "    lsc1_rc.append(risk(lsc1_lower, lsc1_upper, rtest[i]))\n",
    "    lsc1_width.append(jnp.median(lsc1_upper - lsc1_lower))\n",
    "    \n",
    "    # LSCI\n",
    "    lsc2_lower, lsc2_upper = lsci.lsci(rval, xval.reshape(-1, 30*60), xtest[i].reshape(-1, 30*60), pca_state, alpha1, gamma2, 2000)\n",
    "    lsc2_rc.append(risk(lsc2_lower, lsc2_upper, rtest[i]))\n",
    "    lsc2_width.append(jnp.median(lsc2_upper - lsc2_lower))\n",
    "    \n",
    "    # CONF \n",
    "    conf_rc.append(risk(conf_lower, conf_upper, rtest[i]))\n",
    "    conf_width.append(jnp.mean(conf_upper - conf_lower))\n",
    "    \n",
    "    # SUPR\n",
    "    supr_rc.append(risk(supr_lower, supr_upper, rtest[i]))\n",
    "    supr_width.append(jnp.mean(supr_upper - supr_lower))\n",
    "    \n",
    "    # UQNO\n",
    "    uqn1_rc.append(risk(uqn1_lower[i], uqn1_upper[i], rtest[i]))\n",
    "    uqn1_width.append(jnp.mean(uqn1_upper[i] - uqn1_lower[i]))\n",
    "\n",
    "    \n",
    "conf_rc = np.array(conf_rc)\n",
    "supr_rc = np.array(supr_rc)\n",
    "uqn1_rc = np.array(uqn1_rc)\n",
    "lsc1_rc = np.array(lsc1_rc)\n",
    "lsc2_rc = np.array(lsc2_rc)\n",
    "\n",
    "conf_width = np.array(conf_width)\n",
    "supr_width = np.array(supr_width)\n",
    "uqn1_width = np.array(uqn1_width)\n",
    "lsc1_width = np.array(lsc1_width)\n",
    "lsc2_width = np.array(lsc2_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a03e9b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04450710be6a42d99f1b5e715226d282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oracle_rc = []\n",
    "oracle_width = []\n",
    "for i in trange(0, ytest.shape[0]):\n",
    "    \n",
    "    # Oracle    \n",
    "    oracle_lower = jnp.min(rtest[i]) * jnp.ones((30*60,)) - 1e-7\n",
    "    oracle_upper = jnp.max(rtest[i]) * jnp.ones((30*60,)) + 1e-7\n",
    "    oracle_rc.append(risk(oracle_lower, oracle_upper, rtest[i]))\n",
    "    oracle_width.append(jnp.mean(oracle_upper - oracle_lower))\n",
    "\n",
    "oracle_rc = np.array(oracle_rc)\n",
    "oracle_width = np.array(oracle_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2627d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sd = np.std(rtest, axis = 1)\n",
    "\n",
    "risk_control = np.mean(oracle_rc >= 0.99), \\\n",
    "               np.mean(conf_rc >= 0.99), \\\n",
    "               np.mean(supr_rc >= 0.99), \\\n",
    "               np.mean(uqn1_rc >= 0.99), \\\n",
    "               np.mean(lsc1_rc >= 0.99), \\\n",
    "               np.mean(lsc2_rc >= 0.99)\n",
    "\n",
    "width = np.mean(oracle_width), \\\n",
    "        np.mean(conf_width), \\\n",
    "        np.mean(supr_width), \\\n",
    "        np.mean(uqn1_width), \\\n",
    "        np.mean(lsc1_width), \\\n",
    "        np.mean(lsc2_width)\n",
    "\n",
    "risk_cor = 0, \\\n",
    "           np.corrcoef([noise_sd, conf_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, supr_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, uqn1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc2_rc])[0,1]\n",
    "\n",
    "width_cor = np.corrcoef([noise_sd, oracle_width])[0,1], \\\n",
    "            0, \\\n",
    "            0, \\\n",
    "            np.corrcoef([noise_sd, uqn1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc2_width])[0,1]\n",
    "\n",
    "metrics = np.array([risk_control, risk_cor, width, width_cor]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00d6ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     0.     0.73   0.979]\n",
      " [ 0.727 -0.748  1.003  0.   ]\n",
      " [ 0.932 -0.531  1.224  0.   ]\n",
      " [ 0.709 -0.774  0.867  0.968]\n",
      " [ 0.934 -0.14   0.794  0.967]\n",
      " [ 0.884 -0.152  0.78   0.966]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(metrics, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66b6f894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 & 0.000 & 0.730 & 0.979 \\\\\n",
      "0.727 & -0.748 & 1.003 & 0.000 \\\\\n",
      "0.932 & -0.531 & 1.224 & 0.000 \\\\\n",
      "0.709 & -0.774 & 0.867 & 0.968 \\\\\n",
      "0.934 & -0.140 & 0.794 & 0.967 \\\\\n",
      "0.884 & -0.152 & 0.780 & 0.966 \\\\\n"
     ]
    }
   ],
   "source": [
    "for i in range(metrics.shape[0]):\n",
    "    for j in range(metrics.shape[1]):\n",
    "        val = f'{np.round(metrics[i,j], 3):.3f}'\n",
    "        if j < 3:\n",
    "            val += ' & '\n",
    "            print(val, end = '')\n",
    "        else:\n",
    "            val += ' \\\\\\\\'\n",
    "            print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "695afabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_sd = np.std(rtest, axis = 1)[:conf_rc.shape[0]]\n",
    "\n",
    "# risk_control = np.mean(conf_rc >= 0.99), \\\n",
    "#                np.mean(supr_rc >= 0.99), \\\n",
    "#                np.mean(uqn1_rc >= 0.99), \\\n",
    "#                np.mean(lsc1_rc >= 0.99),\n",
    "# #                np.mean(lsc2_rc >= 0.99)\n",
    "\n",
    "# width = np.mean(conf_width), \\\n",
    "#         np.mean(supr_width), \\\n",
    "#         np.mean(uqn1_width), \\\n",
    "#         np.mean(lsc1_width),\n",
    "# #         np.mean(lsc2_width)\n",
    "\n",
    "# risk_cor = np.corrcoef([noise_sd, conf_rc])[0,1], \\\n",
    "#            np.corrcoef([noise_sd, supr_rc])[0,1], \\\n",
    "#            np.corrcoef([noise_sd, uqn1_rc])[0,1], \\\n",
    "#            np.corrcoef([noise_sd, lsc1_rc])[0,1],\n",
    "# #            np.corrcoef([noise_sd, lsc2_rc])[0,1]\n",
    "\n",
    "# width_cor = 0, \\\n",
    "#             0, \\\n",
    "#             np.corrcoef([noise_sd, uqn1_width])[0,1], \\\n",
    "#             np.corrcoef([noise_sd, lsc1_width])[0,1],\n",
    "# #             np.corrcoef([noise_sd, lsc2_width])[0,1]\n",
    "\n",
    "# metrics = np.array([risk_control, risk_cor, width, width_cor]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a30c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46  -0.772  1.048  0.   ]\n",
      " [ 0.88  -0.543  1.224  0.   ]\n",
      " [ 0.29  -0.82   0.931  0.772]\n",
      " [ 0.99  -0.418  1.267  0.764]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(metrics, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c50785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
