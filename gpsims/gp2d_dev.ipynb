{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b7ab1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.stats as stats\n",
    "from jax import jacfwd, jacrev\n",
    "from jax import vmap, grad, jit, random\n",
    "from jax.tree_util import tree_map, tree_flatten, tree_unflatten, tree_leaves\n",
    "\n",
    "import torch_harmonics as th\n",
    "from torch_harmonics.random_fields import GaussianRandomFieldS2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from flax import nnx\n",
    "import optax\n",
    "import pcax\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a92f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../methods')\n",
    "import lsci, supr, conf, uqno\n",
    "os.chdir('../gpsims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a868a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(lower, upper, residual):\n",
    "    return jnp.mean((residual > lower)*(residual < upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bc2a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, lag, horizon):\n",
    "    horizon = horizon-1\n",
    "    y_t = data[(lag + horizon):][:,None]\n",
    "    x_t = np.stack([data[(lag-i-1):(-(i+1+horizon))] for i in range(lag)], axis = 1)\n",
    "    return x_t.copy(), y_t.copy()\n",
    "\n",
    "def torch2jax(x):\n",
    "    return jnp.array(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73293bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANO_layer(nnx.Module):\n",
    "    def __init__(self, width, rngs: nnx.Rngs):\n",
    "        self.linear = nnx.Linear(width, width, rngs=rngs)\n",
    "        # self.bn = nnx.BatchNorm(dmid, rngs=rngs)\n",
    "        # self.dropout = nnx.Dropout(0.2, rngs=rngs)\n",
    "        self.linear_out = nnx.Linear(width, width, rngs=rngs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # channel mix\n",
    "        h = self.linear(x)\n",
    "\n",
    "        # spatial mix\n",
    "        g = jnp.mean(x, axis = (1, 2))[:,None,None,:]\n",
    "\n",
    "        # sum\n",
    "        x = h + g\n",
    "        x = nnx.relu(x)\n",
    "\n",
    "        return self.linear_out(x)\n",
    "\n",
    "class encode_layer(nnx.Module):\n",
    "    def __init__(self, in_dim, out_dim, rngs):\n",
    "        self.linear = nnx.Linear(in_dim, out_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepANO(nnx.Module):\n",
    "    def __init__(self, in_dim, width, out_dim, rngs):\n",
    "        self.encode_layer = encode_layer(in_dim, width, rngs)\n",
    "        self.ano1 = ANO_layer(width, rngs)\n",
    "        self.ano2 = ANO_layer(width, rngs)\n",
    "        self.ano3 = ANO_layer(width, rngs)\n",
    "        self.decode_layer = encode_layer(width, out_dim, rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encode_layer(x)\n",
    "        x = self.ano1(x)\n",
    "        x = self.ano2(x)\n",
    "        x = self.ano3(x)\n",
    "        x = self.decode_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0ea8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANO_layer(nnx.Module):\n",
    "    def __init__(self, width, rngs: nnx.Rngs):\n",
    "        self.conv = nnx.Conv(width, width, (1, 1), rngs=rngs)\n",
    "        self.conv_out = nnx.Conv(width, width, (1, 1), rngs=rngs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # channel mix\n",
    "        h = self.conv(x)\n",
    "\n",
    "        # spatial mix\n",
    "        g = jnp.mean(x, axis = (1, 2))[:,None,None,:]\n",
    "\n",
    "        # sum\n",
    "        x = h + g\n",
    "        x = nnx.relu(x)\n",
    "\n",
    "        return self.conv_out(x)\n",
    "\n",
    "class encode_layer(nnx.Module):\n",
    "    def __init__(self, in_dim, out_dim, rngs):\n",
    "        self.conv = nnx.Conv(in_dim, out_dim, (1, 1), rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class DeepANO(nnx.Module):\n",
    "    def __init__(self, in_dim, width, out_dim, rngs):\n",
    "        self.encode_layer = encode_layer(in_dim, width, rngs)\n",
    "        self.ano1 = ANO_layer(width, rngs)\n",
    "        self.ano2 = ANO_layer(width, rngs)\n",
    "        self.ano3 = ANO_layer(width, rngs)\n",
    "        self.decode_layer = encode_layer(width, out_dim, rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encode_layer(x)\n",
    "        x = self.ano1(x)\n",
    "        x = self.ano2(x)\n",
    "        x = self.ano3(x)\n",
    "        x = self.decode_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62c5ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x, y):\n",
    "    def loss_fn(model):\n",
    "        y_pred = model(x)\n",
    "        return jnp.mean((y_pred - y) ** 2)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads)  # In place updates.\n",
    "\n",
    "    return loss\n",
    "\n",
    "def quant_step(model, optimizer, x, y):\n",
    "    def loss_fn(model):\n",
    "        quant = 1 - 0.1\n",
    "        y_pred = model(x)\n",
    "        y_abs = jnp.abs(y)\n",
    "        resid = y_abs - y_pred\n",
    "        loss = jnp.max(jnp.concat([quant * resid, -(1-quant) * resid], axis = 3), axis = 3)\n",
    "        return jnp.mean(loss)\n",
    "    \n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads)  # in-place updates\n",
    "\n",
    "    return loss\n",
    "\n",
    "train_step = nnx.jit(train_step)\n",
    "quant_step = nnx.jit(quant_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bfb254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 501\n",
    "s = jnp.linspace(-2*math.pi, 2*math.pi, n+1)\n",
    "amp = jnp.sin(s)\n",
    "sd = 1.25 + jnp.sin(s)\n",
    "\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xtrain = gp2d(n+1).numpy()\n",
    "xtrain = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xtrain)\n",
    "xtrain, ytrain = split_data(xtrain, 1, 1)\n",
    "xtrain = xtrain[:,0,:,:,None]\n",
    "ytrain = ytrain[:,0,:,:,None]\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xval = gp2d(n+1).numpy()\n",
    "xval = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xval)\n",
    "xval, yval = split_data(xval, 1, 1)\n",
    "xval = xval[:,0,:,:,None]\n",
    "yval = yval[:,0,:,:,None]\n",
    "\n",
    "gp2d = GaussianRandomFieldS2(nlat = 30)\n",
    "xtest = gp2d(n+1).numpy()\n",
    "xtest = 10 + amp[:,None,None] + sd[:,None,None] * jnp.array(xtest)\n",
    "xtest, ytest = split_data(xtest, 1, 1)\n",
    "xtest = xtest[:,0,:,:,None]\n",
    "ytest = ytest[:,0,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbb07842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.Tensor(xtrain), torch.Tensor(ytrain))\n",
    "train_loader = DataLoader(train_data, batch_size = 30, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eece0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @nnx.jit  # Automatic state management\n",
    "# def train_step(model, optimizer, x, y):\n",
    "#     def loss_fn(model):\n",
    "#         y_pred = model(x)\n",
    "#         y_diff = jnp.diff(y_pred, axis = 0)\n",
    "#         return jnp.mean((y_pred - y) ** 2) + jnp.mean(y_diff**2)\n",
    "\n",
    "#     loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "#     optimizer.update(grads)  # In place updates.\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# epochs = 5\n",
    "# trace = []\n",
    "\n",
    "# model = ClimateNO(1, 32, 1, rngs=nnx.Rngs(0))\n",
    "# optim = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "# rng = random.PRNGKey(0)\n",
    "\n",
    "# for _ in trange(epochs):\n",
    "#     for xt, yt in tqdm(train_loader, leave = False):\n",
    "#         xt = torch2jax(xt)\n",
    "#         yt = torch2jax(yt)\n",
    "        \n",
    "#         loss = train_step(model, optim, xt, yt)\n",
    "#         trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "958bc1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9aeb79de6c4a57bfb5478c043fb29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "trace = []\n",
    "lag, lead = 1, 1\n",
    "\n",
    "model = DeepANO(lag, 50, lead, rngs=nnx.Rngs(0))\n",
    "optim = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "for _ in trange(epochs):\n",
    "    for xt, yt in train_loader:\n",
    "        xt = torch2jax(xt)\n",
    "        yt = torch2jax(yt)\n",
    "        \n",
    "        loss = train_step(model, optim, xt, yt)\n",
    "        trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a446af9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145d9721b70d493db8ab77f462d8efc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quant = DeepANO(lag, 50, lead, rngs=nnx.Rngs(0))\n",
    "optim = nnx.Optimizer(quant, optax.adam(1e-3))\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "for _ in trange(epochs):\n",
    "    for xt, yt in train_loader:\n",
    "        xt = torch2jax(xt)\n",
    "        yt = torch2jax(yt)\n",
    "        \n",
    "        loss = quant_step(quant, optim, xt, yt)\n",
    "        trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "724c148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_step(model, optimizer, x, y):\n",
    "#     def loss_fn(model):\n",
    "#         quant = 1 - 0.1\n",
    "#         y_pred = model(x)\n",
    "#         y_abs = jnp.abs(y)\n",
    "#         resid = y_abs - y_pred\n",
    "#         loss = jnp.max(jnp.concat([quant * resid, -(1-quant) * resid], axis = 3), axis = 3)\n",
    "#         return jnp.mean(loss)\n",
    "    \n",
    "#     loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "#     optimizer.update(grads)  # in-place updates\n",
    "\n",
    "#     return loss\n",
    "# train_step = nnx.jit(train_step)\n",
    "\n",
    "# quant = DeepANO(1, 50, 1, nnx.Rngs(0))\n",
    "# optimizer = nnx.Optimizer(quant, optax.adam(1e-3)) \n",
    "\n",
    "# epochs = 100\n",
    "# nbat = 50\n",
    "# for _ in trange(epochs):\n",
    "#     for i in trange(xtrain.shape[0]//nbat, leave = False):\n",
    "#         xi = xtrain[i*nbat:(i+1)*nbat]\n",
    "#         yi = ytrain[i*nbat:(i+1)*nbat]\n",
    "\n",
    "#         loss = train_step(quant, optimizer, xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a93e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "yval_hat = model(xval)\n",
    "ytest_hat = model(xtest)\n",
    "yval_quant = quant(xval)\n",
    "ytest_quant = quant(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bca5de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nproj = 100\n",
    "gamma1 = 0.2\n",
    "alpha = 0.1\n",
    "nval = xval.shape[0]\n",
    "alpha1 = 1 - jnp.ceil((1-alpha) * (gamma1*nval + 1))/(gamma1*nval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d886b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "yval = yval.reshape(yval.shape[0], -1)\n",
    "yval_hat = yval_hat.reshape(yval_hat.shape[0], -1)\n",
    "pca_state = lsci.phi_state(yval, yval_hat, nproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fa730df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.03918276, dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UQNO lambda estimate\n",
    "yval_quant = yval.reshape(yval_quant.shape[0], -1)\n",
    "ytest_quant = ytest_quant.reshape(ytest_quant.shape[0], -1)\n",
    "\n",
    "alpha = 0.1\n",
    "delta = 0.1\n",
    "m = 30*60\n",
    "tau = 2 * jnp.sqrt(-jnp.log(delta)/(2*m))\n",
    "sg = jnp.abs(yval - yval_hat) / yval_quant\n",
    "sg = jnp.quantile(sg, 1-alpha+tau, axis = (1))\n",
    "nval = sg.shape[0]\n",
    "\n",
    "adj_alpha = 1 - jnp.ceil((nval + 1) * (delta - jnp.exp(-2*m*tau**2)))/nval\n",
    "lam_uqno = jnp.quantile(sg, adj_alpha)\n",
    "lam_uqno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9e46920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abd7bafe054487580cd84731dcaa1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nproj = 150\n",
    "gamma1 = 0.1\n",
    "alpha = 0.1\n",
    "nval = xval.shape[0]\n",
    "alpha1 = 1 - jnp.ceil((1-alpha) * (gamma1*nval + 1))/(gamma1*nval)\n",
    "\n",
    "lsc1_rc = []\n",
    "lsc1_width = []\n",
    "\n",
    "conf_rc = []\n",
    "conf_width = []\n",
    "\n",
    "supr_rc = []\n",
    "supr_width = []\n",
    "\n",
    "uqn1_rc = []\n",
    "uqn1_width = []\n",
    "\n",
    "yval = yval.reshape(yval.shape[0], -1)\n",
    "yval_hat = yval_hat.reshape(yval_hat.shape[0], -1)\n",
    "pca_state = lsci.phi_state(yval, yval_hat, nproj)\n",
    "\n",
    "rval = (yval - yval_hat).squeeze().reshape(-1, 30*60)\n",
    "rtest = (ytest - ytest_hat).squeeze().reshape(-1, 30*60)\n",
    "\n",
    "conf_lower, conf_upper = conf.conf_band(rval, pca_state, alpha)\n",
    "supr_lower, supr_upper = supr.supr_band(rval, alpha)\n",
    "uqn1_lower, uqn1_upper = uqno.uqno_band(ytest_quant, lam_uqno)\n",
    "\n",
    "for i in trange(0, 100):\n",
    "    \n",
    "    # LSCI\n",
    "    lsc1_lower, lsc1_upper = lsci.lsci((yval - yval_hat).reshape(-1, 30*60), xval.reshape(-1, 30*60), xtest[i].reshape(-1, 30*60), pca_state, alpha1, gamma1, 2000)\n",
    "    lsc1_rc.append(risk(lsc1_lower, lsc1_upper, rtest[i]))\n",
    "    lsc1_width.append(jnp.median(lsc1_upper - lsc1_lower))\n",
    "    \n",
    "    # CONF \n",
    "    conf_rc.append(risk(conf_lower, conf_upper, rtest[i]))\n",
    "    conf_width.append(jnp.mean(conf_upper - conf_lower))\n",
    "    \n",
    "    # SUPR\n",
    "    supr_rc.append(risk(supr_lower, supr_upper, rtest[i]))\n",
    "    supr_width.append(jnp.mean(supr_upper - supr_lower))\n",
    "    \n",
    "    # UQNO\n",
    "    uqn1_rc.append(risk(uqn1_lower[i], uqn1_upper[i], rtest[i]))\n",
    "    uqn1_width.append(jnp.mean(uqn1_upper[i] - uqn1_lower[i]))\n",
    "\n",
    "    \n",
    "conf_rc = np.array(conf_rc)\n",
    "supr_rc = np.array(supr_rc)\n",
    "uqn1_rc = np.array(uqn1_rc)\n",
    "lsc1_rc = np.array(lsc1_rc)\n",
    "\n",
    "conf_width = np.array(conf_width)\n",
    "supr_width = np.array(supr_width)\n",
    "uqn1_width = np.array(uqn1_width)\n",
    "lsc1_width = np.array(lsc1_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "695afabe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsc2_rc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m noise_sd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(rtest, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[:conf_rc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      3\u001b[0m risk_control \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(conf_rc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m), \\\n\u001b[1;32m      4\u001b[0m                np\u001b[38;5;241m.\u001b[39mmean(supr_rc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m), \\\n\u001b[1;32m      5\u001b[0m                np\u001b[38;5;241m.\u001b[39mmean(uqn1_rc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m), \\\n\u001b[1;32m      6\u001b[0m                np\u001b[38;5;241m.\u001b[39mmean(lsc1_rc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m),  \\\n\u001b[0;32m----> 7\u001b[0m                np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mlsc2_rc\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m)\n\u001b[1;32m      9\u001b[0m width \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(conf_width), \\\n\u001b[1;32m     10\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(supr_width), \\\n\u001b[1;32m     11\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(uqn1_width), \\\n\u001b[1;32m     12\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(lsc1_width), \\\n\u001b[1;32m     13\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(lsc2_width)\n\u001b[1;32m     15\u001b[0m risk_cor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef([noise_sd, conf_rc])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], \\\n\u001b[1;32m     16\u001b[0m            np\u001b[38;5;241m.\u001b[39mcorrcoef([noise_sd, supr_rc])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], \\\n\u001b[1;32m     17\u001b[0m            np\u001b[38;5;241m.\u001b[39mcorrcoef([noise_sd, uqn1_rc])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], \\\n\u001b[1;32m     18\u001b[0m            np\u001b[38;5;241m.\u001b[39mcorrcoef([noise_sd, lsc1_rc])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], \\\n\u001b[1;32m     19\u001b[0m            np\u001b[38;5;241m.\u001b[39mcorrcoef([noise_sd, lsc2_rc])[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lsc2_rc' is not defined"
     ]
    }
   ],
   "source": [
    "noise_sd = np.std(rtest, axis = 1)[:conf_rc.shape[0]]\n",
    "\n",
    "risk_control = np.mean(conf_rc >= 0.99), \\\n",
    "               np.mean(supr_rc >= 0.99), \\\n",
    "               np.mean(uqn1_rc >= 0.99), \\\n",
    "               np.mean(lsc1_rc >= 0.99),  \\\n",
    "               np.mean(lsc2_rc >= 0.99)\n",
    "\n",
    "width = np.mean(conf_width), \\\n",
    "        np.mean(supr_width), \\\n",
    "        np.mean(uqn1_width), \\\n",
    "        np.mean(lsc1_width), \\\n",
    "        np.mean(lsc2_width)\n",
    "\n",
    "risk_cor = np.corrcoef([noise_sd, conf_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, supr_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, uqn1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc1_rc])[0,1], \\\n",
    "           np.corrcoef([noise_sd, lsc2_rc])[0,1]\n",
    "\n",
    "width_cor = 0, \\\n",
    "            0, \\\n",
    "            np.corrcoef([noise_sd, uqn1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc1_width])[0,1], \\\n",
    "            np.corrcoef([noise_sd, lsc2_width])[0,1]\n",
    "\n",
    "metrics = np.array([risk_control, risk_cor, width, width_cor]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(metrics, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c50785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
